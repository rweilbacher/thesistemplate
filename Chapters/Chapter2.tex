% Chapter 1

\chapter{The basic safety hypervisor} % Main chapter title

\label{Chapter2} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

% IMPORTANT Add a section about IPC and interpartition communication
% IMPORTANT Do I talk enough about whether or not developers offer para or full or both?
% IMPORTANT Talk about supported hardware, v7 vs v8 and breadth of platforms

\section{Architecture}
% NOTE Where to talk about static configuration?
Now that any misconceptions concerning the purpose of the safety hypervisor have been cleared up, it is time to examine its architecture and features. For this, a "basic safety hypervisor" will be proposed, that embodies the typical characteristics of a microkernel based safety hypervisor. Where there is no discernible consensus, differences will be highlighted.

% NOTE I think I am mixing microkernel architecture with hypervisor architecture
\subsection{Minimal trusted computing base}
Minimality is the most essential principal of microkernel design. It proves particularly useful for hypervisors with a focus on certification because a strong rule of thumb is: Less code means less verification effort as well as faults \cite{Lipow.1982}.  
Where the original microkernels were just thin wrapper around the hardware, a \gls{CPU} driver so to speak, the microkernel based hypervisor adds a bit more code for the virtualization \cite{Heiser.2010}. These systems have around ten thousand lines of code.

\subsection{Capability-based access control}
Capabilities are unforgeable tokens that grant access rights to an object. They contain the identification of the object and associated rights, for example read and write.
They can be given to other entities which in turn grants them access according to the capability \cite{Levy.1984}. A capability could be for a specific memory region, a communication endpoint or to a hypervisor \gls{API} call.

This mechanism for access control has dominated in microkernels because of its flexibility and because it doesn't require extensive kernel involvement. Since, the typical safety hypervisor sits on top of a microkernel, this mechanism has propagated to them as well.

\subsection{Scheduling}
% NOTE I might have to explain or at least source what these are
% NOTE Better name?
There is really no unified scheduling behavior that all hypervisors share. Global scheduling is the typical behavior with common algorithms being preemptive priority based scheduling and time-sliced round-robin scheduling. Additionally, hypervisors running on multicore platforms usually have the ability to assign complete cores to guests.

Some also offer hierarchical scheduling, where a so-called container task is scheduled that then schedules its children according to a global scheduling algorithm. This can have the benefit of reducing scheduling slack \cite{MalcolmS.Mollison.2010}. 

Whatever the specific implementation is, at the very least it satisfies the temporal separation requirement from the section \ref{separation-arch}. 

\paragraph{Real-time requirements}
Additionally, the basic safety hypervisor's scheduling is deterministic and overhead is suitably low. This means that a worst-case execution time analysis can be carried out and real-time requirements can conceptually be satisfied. However, to what precise degree can't really be generalized.
\begin{comment}
\subsection{Static configuration}
Any mechanism to increase a guests rights at runtime poses the risk of exploitation, be it accidental or purposeful. That is why these systems are typically statically configured and if configuration runtime is at all possible, it is restricted to reducing privilege. For example, a guest that is allowed to spawn other guests may give them his own rights or less than his own but never more.
\end{comment}

\subsection{Explicit access}
Any configuration that grants rights, be it communication with another guest or resource access, has to be explicitly enabled by the system integrator. This makes sure that no unintended access is granted to guests that could potentially compromise the system.
\subsection{Available guest environments}
% TODO Explain what a guest environment is
The typical hypervisor supports several different guest environments.
\paragraph{Paravirtualized versus fully virtualized}
A key distinction between virtualized guest environments is their virtualization type \ref{hw-virt}. Expect paravirtualization to always be available in a hypervisor, full virtualization support on the other hand is more rare. One reason could be that virtualization extensions are still relatively new, especially on ARM processors. In any case, full virtualization can only be offered if the platform supports hardware virtualization extensions.

% NOTE Meh...
% TODO Source?
There also appears to be some contention on whether or not full virtualization can be as performant, and more importantly as deterministic, as paravirtualization. A lack of determinism could endanger certification, if the device has hard real-time requirements. This thesis does not try to offer evidence for either claim, whether or not full virtualization can be justified in front of the regulatory body depends on the specific scenario. 

% TODO Move this section
% IMPORTANT Move it!
Nevertheless, the importance of the outcome is likely not trivial, since full virtualization has a number of advantages: First, it means the cost and time of modifying the guest operating system can be saved. Alternatively, it could be reduced by using an already modified \gls{OS}, provided by the hypervisor developer but this is bound to be a very restricted choice that further increase the dependence on the developer.

Second, the amount of viable operating systems is higher. The modification efforts to an \gls{OS} can only be made if the source code is available, but for many commercial products this is not the case. 

Ultimately, it is important to verify that full virtualization is plausible for your device and analyze what the consequences of a lack thereof are.
\paragraph{\gls{RTOS} and \gls{GPOS}}
The basic hypervisor offers both \gls{RTOS} and \gls{GPOS} guests. What kinds and how much variety depends on the points raised in the previous section about virtualization types. 
\paragraph{Native \gls{API}}
Typically there is also the option to have guests that are not a fully fledged operating system but a virtualized bare-metal environment with access to the hypervisor \gls{API} instead. 

The applications of this are wide-ranging but one example would be to implement a driver that is required by both an \gls{RTOS} and \gls{GPOS} running on the system. Both partitions could then use the hypervisor's messaging mechanism to communicate with the driver. This would be especially useful for peripherals that are difficult to share normally.
\subsection{Hardware abstraction}
While the hypervisor does not get around having to implement a minimal \gls{BSP} for each platform, it can offer significant hardware abstraction to its guests. The \keyword{Native \gls{API}} mentioned in the previous section is not just available to bare-metal guests but also to virtualized ones. Some examples of this are: Getting information about the system, communication with other guests and centralized logging.

%----------------------------------------------------------------------------------------
\section{Initial considerations}
Although the considerations for choosing a hypervisor implementation will be outlined later in the thesis, in section \ref{how-to-decide}, some crucial factors need to be elaborated here to avoid confusion.
\subsection{First- or third-party hypervisor}
A manufacturer has the option to either license a third-party hypervisor or develop his own solution. The development costs of a third-party hypervisor are effectively shared with many parties over the course of many projects, whereas the development costs of a first-party hypervisor are typically only shared over the course of many projects in a single company. However, developing one's own hypervisor provides the maximum amount of control over functionality and development cycle.

Additionally, it means that the best possible subject matter experts on the hypervisor are always available to the manufacturer. But here also lies another big problem: Developing a custom hypervisor not only requires the initial development costs but also the costs of hiring or developing the talent required. A third-party already has these capacities and can therefore also typically go beyond the absolute necessity in terms of functionality.

Ultimately, the more prudent approach is probably licensing a third-party hypervisor but in some cases it may be beneficial to have full control over the environment.

\subsection{Security}
Security will not be a consideration in this thesis, only a word of warning will be issued. It may seem logical to assume that a hypervisor can provide security as well as safety and while it may not initially be a bad idea to have separation between security-critical and non-security-critical software it is not that simple. A hypervisor offers a much greater attack incentive, as a compromisation of the platform could be used to attack a lot of different devices. It is also questionable whether or not the goals of security and safety align. A manufacturer doesn't want to modify a certified device or at least do it in bulk to minimize the cost of recertification. Building a secure device on the other hand often requires frequent updates to fix newly found attack vectors. So the security of any given hypervisor implementation should not be taken for granted and analyzed with scrutiny.
%----------------------------------------------------------------------------------------

\section{Limitations}
Before getting into the full-fledged analysis it is best to expose some limitations of the current safety hypervisor landscape. 
\subsection{Current hardware restrictions}
Hypervisors are overall still limited to the more powerful \keyword{application processors} and have not really penetrated the \keyword{microcontroller} market. Using a hypervisor is also not possible if a specialized processor, like a \gls{DSP}, will be the only processor in the system. Although, this restriction may be lifted in the future.  There are several reasons for the hypervisor's hardware restrictions. 

% PHRASING 
First of all, microcontrollers typically have no \gls{MMU} only an \gls{MPU} or no memory protection at all. Hypervisors need at least some hardware memory protection, as the corresponding software isolation is far too slow. \gls{MPU}s have a limited number of partitions they can isolate and therefore impose uncomfortable restrictions on hypervisor developers and users.

Second, the hardware virtualization extensions are not yet available on microcontrollers. And even though the typical safety hypervisor prefers paravirtualized guests, virtualization extensions are still beneficial for preventing the guest from doing things it is not supposed to. ARM, for example, offers a trap mechanism that allows the hypervisor to disable certain instructions and special registers for the guest \cite{ARM.v8.2018}. 

And finally, a hypervisor is fundamentally about isolating software components from each other. It is more likely that this is necessary on a stronger processor and not on a microcontroller.

However, with all of these restrictions laid out, there are developments that aim to make hypervisors viable on microcontrollers. Read more about this in section \ref{tech-progress}.

\subsection{Effective multicore isolation}
% NOTE Maybe add a graphic
Imagine a system with two partitions, one safety-critical one not safety-critical, that runs on a two-core \gls{CPU} with a shared cache between the two cores. During its allocated time the safety-critical partition may fill up the cache with relevant values. Once the non-safety-critical software runs it can evict all of the cache values by populating it with its own values. This can lead to large and potentially unpredictable interference across domains \cite{AlessandroBiondi.2018}.

In the best case this scenario just leads to an excessively pessimistic \gls{WCET} analysis and to compensate this the safety-critical partition would get a lot more allocated time than it actually needed, leading to a worse average case performance. There are efforts to solve this issue reliably \cite{PaoloModica.2018}.

%----------------------------------------------------------------------------------------

